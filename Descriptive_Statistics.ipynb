{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b516ae-b941-4a02-8796-65b02f148656",
   "metadata": {},
   "source": [
    "## Merge Two files into Single File\n",
    "#### Check the name of common column and edit it if you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6068708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_a_path = 'BreastCancer_addDummyColumn.csv'\n",
    "file_b_path = 'BreastCancer_addCountColumns_Primary_Secondary.csv'\n",
    "\n",
    "df_a = pd.read_csv(file_a_path)\n",
    "df_b = pd.read_csv(file_b_path)\n",
    "\n",
    "merged_df = pd.merge(df_a, df_b, left_on='protocolSection.identificationModule.nctId', right_on='NCT number', how='inner')\n",
    "\n",
    "merged_df.to_csv('BreastCancer_Merged_addDummyColumn_addCountColumns_Primary_Secondary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f825083-37ea-4dd0-a2bc-c767f9b652be",
   "metadata": {},
   "source": [
    "#### If you execute above cell, you can see the same data with different column in the single file. \n",
    "#### Drop one of those column to be looked clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cccf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns=['NCT number'], inplace=True)\n",
    "merged_df.to_csv('BreastCancer_Merged_addDummyColumn_addCountColumns_Primary_Secondary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284877ca-c436-48ed-89c4-20a689e2d269",
   "metadata": {},
   "source": [
    "## When working on large files multiple times, it's more efficient to preload the file before starting your tasks, as this can save a lot of time.\n",
    "## Adjust the conditions as needed based on the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('merged_Dump.csv')  # Replace with your actual file path\n",
    "\n",
    "# Adjust the conditions. Belows are examples\n",
    "df = df[df['protocolSection.designModule.designInfo.interventionModel'] == 'PARALLEL']\n",
    "df = df[(df['breast_cancer_dummy'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d7f50-76eb-4490-9d05-3f180131ea93",
   "metadata": {},
   "source": [
    "#### Filter the data if the interventionmodel is parallel and condtions are breast cancer.\n",
    "#### Scope Down the Primary data\n",
    "#### Normalize the measure title using function and calculate the frequency of measure title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('your_data_file.csv')  # Replace with your actual file path\n",
    "\n",
    "# Filter rows where intervention model is 'PARALLEL'\n",
    "df = df[df['protocolSection.designModule.designInfo.interventionModel'] == 'PARALLEL']\n",
    "\n",
    "# Function to convert string representation of lists and dicts to Python objects\n",
    "def process_data(data):\n",
    "    if pd.isna(data):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(data)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Function to check for 'breast cancer' presence\n",
    "def has_breast_cancer(data):\n",
    "    return 'breast cancer' in data.lower()\n",
    "\n",
    "# Categorize the measure title for relevance\n",
    "def categorize_string(s):\n",
    "    patterns = {\n",
    "        'PFS': r'progression[-\\s]*free[-\\s]*survival|pfs',\n",
    "        'DFS': r'disease[-\\s]*free[-\\s]*survival|dfs',\n",
    "        'OS': r'\\boverall[-\\s]*survival\\b|\\bos\\b',\n",
    "        'ORR': r'objective[-\\s]*response[-\\s]*rate|overall[-\\s]*response[-\\s]*rate|orr\\b'\n",
    "    }\n",
    "    s = s.lower()\n",
    "    for key, pattern in patterns.items():\n",
    "        if re.search(pattern, s):\n",
    "            return key\n",
    "    return 'Others'  # Return 'Others' if no category matches\n",
    "\n",
    "# Processing function for outcome measures\n",
    "def process_outcome_measures(data):\n",
    "    outcomes = process_data(data)\n",
    "    titles = [outcome.get('title', '') for outcome in outcomes if outcome.get('type') == 'PRIMARY']\n",
    "    return [categorize_string(title) for title in titles]\n",
    "\n",
    "# Filter rows containing 'breast cancer' and process outcome measures\n",
    "df['hasBreastCancer'] = df.apply(\n",
    "    lambda row: has_breast_cancer(\n",
    "        process_conditions(row['protocolSection.conditionsModule.conditions']),\n",
    "        process_conditions(row['derivedSection.conditionBrowseModule.meshes'])\n",
    "    ), axis=1)\n",
    "\n",
    "filtered_df = df[df['hasBreastCancer']]\n",
    "\n",
    "# Process outcome measures for filtered rows\n",
    "filtered_df['Processed Titles'] = filtered_df['resultsSection.outcomeMeasuresModule.outcomeMeasures'].apply(process_outcome_measures)\n",
    "\n",
    "# Flatten the list of titles and count the occurrences\n",
    "title_counter = Counter([title for sublist in filtered_df['Processed Titles'] for title in sublist])\n",
    "\n",
    "# Create a DataFrame from the counter for easy handling\n",
    "title_stats_df = pd.DataFrame(title_counter.items(), columns=['Title', 'Count'])\n",
    "title_stats_df['Frequency'] = (title_stats_df['Count'] / title_stats_df['Count'].sum() * 100).round(3)\n",
    "\n",
    "# Optionally, save to CSV\n",
    "title_stats_df.to_csv('breast_cancer_titles_frequency.csv', index=False)\n",
    "\n",
    "print(title_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for 'cancer' in a list of strings\n",
    "def has_cancer_in_list(conditions_list):\n",
    "    # Check if the input is NaN or not a string before processing\n",
    "    if pd.isna(conditions_list) or not isinstance(conditions_list, str):\n",
    "        return False\n",
    "    try:\n",
    "        conditions_list = ast.literal_eval(conditions_list)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "    return any('cancer' in condition.lower() for condition in conditions_list if isinstance(conditions_list, list))\n",
    "\n",
    "def has_cancer_in_dict_list(meshes_list):\n",
    "    # Check if the input is NaN or not a string before processing\n",
    "    if pd.isna(meshes_list) or not isinstance(meshes_list, str):\n",
    "        return False\n",
    "    try:\n",
    "        meshes_list = ast.literal_eval(meshes_list)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "    return any('cancer' in mesh['term'].lower() for mesh in meshes_list if isinstance(meshes_list, list) and isinstance(mesh, dict) and 'term' in mesh)\n",
    "\n",
    "# Apply the functions to filter the DataFrame where 'hasResult' is True or False\n",
    "df['hasCancer'] = df.apply(lambda row: has_cancer_in_list(row['protocolSection.conditionsModule.conditions']) or\n",
    "                                          has_cancer_in_dict_list(row['derivedSection.conditionBrowseModule.meshes']), axis=1)\n",
    "\n",
    "# Count occurrences of 'hasCancer' when 'hasResult' is True\n",
    "count_true = df[df['hasResults'] == True]['hasCancer'].sum()\n",
    "# Count occurrences of 'hasCancer' when 'hasResult' is False\n",
    "count_false = df[df['hasResults'] == 'FALSE']['hasCancer'].sum()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of 'hasCancer' when 'hasResult' is True:\", count_true)\n",
    "print(\"Number of 'hasCancer' when 'hasResult' is False:\", count_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Define function to process conditions and convert them from string to list if needed\n",
    "def process_conditions(data):\n",
    "    if pd.isna(data):\n",
    "        return []\n",
    "    if isinstance(data, str):\n",
    "        try:\n",
    "            data = ast.literal_eval(data)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return data\n",
    "\n",
    "# Define function to check for 'breast cancer' in a list of strings or dictionaries\n",
    "def has_breast_cancer(conditions_list, dict_list):\n",
    "    if any('breast cancer' in condition.lower() for condition in conditions_list):\n",
    "        return True\n",
    "    if any('breast cancer' in mesh['term'].lower() for mesh in dict_list if 'term' in mesh):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Load the CSV file\n",
    "# df = pd.read_csv('Cancer_Dump_noResult.csv')\n",
    "\n",
    "# Apply the functions to check for breast cancer presence in each row\n",
    "df['hasBreastCancer'] = df.apply(\n",
    "    lambda row: has_breast_cancer(\n",
    "        process_conditions(row['protocolSection.conditionsModule.conditions']),\n",
    "        process_conditions(row['derivedSection.conditionBrowseModule.meshes'])\n",
    "    ), axis=1)\n",
    "\n",
    "# Count occurrences of 'hasBreastCancer' when 'hasResults' is True\n",
    "count_true = df[df['hasResults'] == True]['hasBreastCancer'].sum()\n",
    "# Count occurrences of 'hasBreastCancer' when 'hasResults' is False\n",
    "count_false = df[df['hasResults'] == False]['hasBreastCancer'].sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of 'breast cancer' entries when 'hasResults' is True:\", count_true)\n",
    "print(\"Number of 'breast cancer' entries when 'hasResults' is False:\", count_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Function to convert string representation of lists and dicts to Python objects\n",
    "def process_data(data):\n",
    "    if pd.isna(data):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(data)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Function to check for 'breast cancer' presence\n",
    "def has_breast_cancer(data):\n",
    "    return 'breast cancer' in data.lower()\n",
    "\n",
    "# Categorize the measure title for relevance\n",
    "def categorize_string(s):\n",
    "    patterns = {\n",
    "        'PFS': r'progression[-\\s]*free[-\\s]*survival|pfs',\n",
    "        'DFS': r'disease[-\\s]*free[-\\s]*survival|dfs',\n",
    "        'OS': r'\\boverall[-\\s]*survival\\b|\\bos\\b',\n",
    "        'ORR': r'objective[-\\s]*response[-\\s]*rate|overall[-\\s]*response[-\\s]*rate|orr\\b'\n",
    "    }\n",
    "    s = s.lower()\n",
    "    for key, pattern in patterns.items():\n",
    "        if re.search(pattern, s):\n",
    "            return key\n",
    "    return 'others'\n",
    "\n",
    "# Processing function for outcome measures\n",
    "def process_outcome_measures(data):\n",
    "    outcomes = process_data(data)\n",
    "    # titles = [outcome.get('title', '') for outcome in outcomes if outcome.get('type') == 'PRIMARY']\n",
    "    titles = [outcome.get('measure', '') for outcome in outcomes]\n",
    "    return [categorize_string(title) for title in titles if categorize_string(title)]\n",
    "\n",
    "# # Filter rows containing 'breast cancer' and process outcome measures\n",
    "# df['hasBreastCancer'] = df.apply(lambda row: any(has_breast_cancer(cond) for cond in process_data(row['protocolSection.conditionsModule.conditions'])) or\n",
    "#                                                   any(has_breast_cancer(mesh['term']) for mesh in process_data(row['derivedSection.conditionBrowseModule.meshes']) if 'term' in mesh), axis=1)\n",
    "\n",
    "# filtered_df = df[df['hasBreastCancer']]\n",
    "\n",
    "# Process outcome measures for filtered rows\n",
    "df['Processed Titles'] = df['protocolSection.outcomesModule.secondaryOutcomes'].apply(process_outcome_measures)\n",
    "\n",
    "# Flatten the list of titles and count the occurrences\n",
    "title_counter = Counter([title for sublist in df['Processed Titles'] for title in sublist])\n",
    "\n",
    "# Create a DataFrame from the counter for easy handling\n",
    "title_stats_df = pd.DataFrame(title_counter.items(), columns=['Title', 'Count'])\n",
    "title_stats_df['Frequency'] = (title_stats_df['Count'] / title_stats_df['Count'].sum() * 100).round(3)\n",
    "print(title_stats_df)\n",
    "# Optionally, save to CSV\n",
    "# title_stats_df.to_csv('breast_cancer_noResult_primary_title_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb0882-62d5-4e32-9478-dd5ef58c8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('Valid_Parallel_with_DrugId_and_Disease.csv')\n",
    "\n",
    "# Include the Primary/Secondary but exclude the Difference in \"Column name\"\n",
    "primary_columns = [col for col in df.columns if 'PRIMARY' in col and 'Differences' not in col]\n",
    "secondary_columns = [col for col in df.columns if 'SECONDARY' in col and 'Differences' not in col]\n",
    "\n",
    "def extract_number(col):\n",
    "    match = re.search(r'(PRIMARY|SECONDARY)(\\d+)', col)\n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    return None\n",
    "\n",
    "def max_numbered_non_null(row, columns):\n",
    "    max_index = 0\n",
    "    for col in columns:\n",
    "        if pd.notna(row[col]):\n",
    "            current_index = extract_number(col)\n",
    "            if current_index > max_index:\n",
    "                max_index = current_index\n",
    "    return max_index \n",
    "    \n",
    "df['Max_Primary'] = df.apply(lambda row: max_numbered_non_null(row, primary_columns), axis=1)\n",
    "df['Max_Secondary'] = df.apply(lambda row: max_numbered_non_null(row, secondary_columns), axis=1)\n",
    "\n",
    "# Calculate the sum of Max_Primary_Number per Disease ID and Disease Name\n",
    "disease_summary = df.groupby(['Disease ID', 'Disease Name'])['Max_Secondary'].sum().reset_index(name='Sum of Max_Primary_Number')\n",
    "\n",
    "# Sort the results in descending order of Sum of Max_Primary_Number and extract the top 3 entries.\n",
    "top_3_diseases = disease_summary.sort_values(by='Sum of Max_Primary_Number', ascending=False).head(3)\n",
    "\n",
    "print(\"Top 3 Disease IDs with the highest sum of Max_Primary_Number:\")\n",
    "print(top_3_diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a780da7-122b-44cb-bbe4-4405f56966c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('Output_Valid_SingleGroup.csv')\n",
    "\n",
    "primary_columns = [col for col in df.columns if 'PRIMARY' in col and 'Differences' not in col]\n",
    "secondary_columns = [col for col in df.columns if 'SECONDARY' in col and 'Differences' not in col]\n",
    "\n",
    "def extract_number(col):\n",
    "    match = re.search(r'(PRIMARY|SECONDARY)(\\d+)', col)\n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    return None\n",
    "\n",
    "def max_numbered_non_null(row, columns):\n",
    "    max_index = 0\n",
    "    for col in columns:\n",
    "        if pd.notna(row[col]):\n",
    "            current_index = extract_number(col)\n",
    "            if current_index > max_index:\n",
    "                max_index = current_index\n",
    "    return max_index \n",
    "    \n",
    "df['Max_Primary'] = df.apply(lambda row: max_numbered_non_null(row, primary_columns), axis=1)\n",
    "df['Max_Secondary'] = df.apply(lambda row: max_numbered_non_null(row, secondary_columns), axis=1)\n",
    "\n",
    "primary_min = df['Max_Primary'].min()\n",
    "primary_max = df['Max_Primary'].max()\n",
    "primary_avg = df['Max_Primary'].mean()\n",
    "primary_std = df['Max_Primary'].std()\n",
    "\n",
    "secondary_min = df['Max_Secondary'].min()\n",
    "secondary_max = df['Max_Secondary'].max()\n",
    "secondary_avg = df['Max_Secondary'].mean()\n",
    "secondary_std = df['Max_Secondary'].std()\n",
    "\n",
    "print(f\"Primary - Min: {primary_min}, Max: {primary_max}, Avg: {primary_avg:.2f}, Std : {primary_std:.2f}\")\n",
    "print(f\"Secondary - Min: {secondary_min}, Max: {secondary_max}, Avg: {secondary_avg:.2f}, Std : {secondary_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3ce3f-75d5-466e-b5df-a1e31bfc4c38",
   "metadata": {},
   "source": [
    "### Make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc449a4d-2836-407d-b5ed-a3da15202ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting Max_Primary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Max_Primary'], bins=range(100,301), color='green', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of the number of Primary Outcomes in Valid SingleGroup')\n",
    "plt.xlabel('Primary Outcomes')\n",
    "plt.ylabel('Trials')\n",
    "# plt.xticks(range(1, df['Max_Primary'].max() + 1))\n",
    "plt.grid(True)\n",
    "plt.savefig('PrimaryOutcomes_ValidSingelGroup_100_300.png')\n",
    "print('Save the graph of PrimaryOutcome')\n",
    "plt.show()\n",
    "\n",
    "# # Plotting Max_Secondary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Max_Secondary'], bins=range(1, df['Max_Secondary'].max() + 2), color='red', alpha=0.7, edgecolor='red')\n",
    "plt.title('Distribution of the number of Secondary Outcomes')\n",
    "plt.xlabel('Secondary Outcomes')\n",
    "plt.ylabel('Trials')\n",
    "# plt.xticks(range(1, df['Max_Secondary'].max() + 1))\n",
    "plt.grid(True)\n",
    "plt.savefig('SecondaryOutcomes_ValidParallel.png')\n",
    "print('Save the graph of SecondaryOutcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f6560-467b-40fb-9fdc-78cac2970305",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_zero_nct = df[df['Max_Primary'] == 0]['NCT number']\n",
    "secondary_zero_nct = df[df['Max_Secondary'] == 0]['NCT number']\n",
    "both_zero_nct = df[(df['Max_Primary'] == 0) & (df['Max_Secondary'] == 0)]['NCT number']\n",
    "\n",
    "both_zero_nct.to_csv('Primary_Secondary_BothZero_NCT_Numbers_ValidParallel.txt', index=False, header=None)\n",
    "print(\"Completed writing NCT numbers to text files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb7836-8b65-461f-bd63-cf1d4dbb76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distribution of Max_Primary\n",
    "primary_distribution = df['Max_Primary'].value_counts().sort_index()\n",
    "\n",
    "# Convert the Series to DataFrame for easier CSV output\n",
    "primary_distribution_df = primary_distribution.reset_index()\n",
    "primary_distribution_df.columns = ['# of Primary', '# of Trials']\n",
    "\n",
    "# Save the distribution to a CSV file\n",
    "primary_distribution_df.to_csv('Primary_Distribution_ValidSingleGroup.csv', index=False)\n",
    "print(\"Max_Primary distribution has been saved to Max_Primary_Distribution.csv.\")\n",
    "\n",
    "# Calculate the distribution of Max_Primary\n",
    "primary_distribution = df['Max_Secondary'].value_counts().sort_index()\n",
    "\n",
    "# Convert the Series to DataFrame for easier CSV output\n",
    "primary_distribution_df = primary_distribution.reset_index()\n",
    "primary_distribution_df.columns = ['# of Secondary', '# of Trials']\n",
    "\n",
    "# Save the distribution to a CSV file\n",
    "primary_distribution_df.to_csv('Secondary_Distribution_ValidSingleGroup.csv', index=False)\n",
    "print(\"Max_Secondary distribution has been saved to Max_Secondary_Distribution.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cec35-26a1-4c42-9a85-2b6704fc5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('0501_ValidParallel_Sample10.csv')\n",
    "\n",
    "primary_columns = [col for col in df.columns if 'PRIMARY' in col and 'Differences' not in col]\n",
    "secondary_columns = [col for col in df.columns if 'SECONDARY' in col and 'Differences' not in col]\n",
    "\n",
    "def extract_number(col):\n",
    "    match = re.search(r'(PRIMARY|SECONDARY)(\\d+)', col)\n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    return None\n",
    "\n",
    "def max_numbered_non_null(row, columns):\n",
    "    max_index = 0\n",
    "    for col in columns:\n",
    "        if pd.notna(row[col]):\n",
    "            current_index = extract_number(col)\n",
    "            if current_index > max_index:\n",
    "                max_index = current_index\n",
    "    return max_index \n",
    "    \n",
    "df['Max_Primary'] = df.apply(lambda row: max_numbered_non_null(row, primary_columns), axis=1)\n",
    "df['Max_Secondary'] = df.apply(lambda row: max_numbered_non_null(row, secondary_columns), axis=1)\n",
    "\n",
    "print(df[['NCT number', 'Max_Primary', 'Max_Secondary']])\n",
    "# #Graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(primary_count_distribution.index, primary_count_distribution.values, color='skyblue')\n",
    "# plt.xlabel('Primary Outcomes')\n",
    "# plt.ylabel('Trials')\n",
    "# plt.title('Number of Trials per primary Outcomes in Valid Parallel')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# plt.savefig('PrimaryOutcome_ValidParallel.png')\n",
    "\n",
    "# # Calculate descriptive statistics\n",
    "# min_value = df['Primary_Count'].min()\n",
    "# max_value = df['Primary_Count'].max()\n",
    "# mean_value = df['Primary_Count'].mean()\n",
    "# std_dev = df['Primary_Count'].std()\n",
    "\n",
    "# # Print descriptive statistics\n",
    "# print(f\"Minimum number of non-null PRIMARY entries: {min_value}\")\n",
    "# print(f\"Maximum number of non-null PRIMARY entries: {max_value}\")\n",
    "# print(f\"Mean number of non-null PRIMARY entries: {mean_value:.2f}\")\n",
    "# print(f\"Standard deviation: {std_dev:.2f}\")\n",
    "# primary_zero_nct = df[df['Max_Primary_Number'] == 0]['NCT number']\n",
    "# primary_zero_nct = df[df['Primary_Count']==1026]['NCT number']\n",
    "# print(primary_zero_nct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd61c2-a61a-48fc-a298-18b4f03acc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read .csv file\n",
    "df = pd.read_csv('Output_Valid_SingleGroup.csv')\n",
    "\n",
    "# calculate the mean of columne 'seriousEvents'\n",
    "serious_events_mean = df['serious Adverse Events'].mean()\n",
    "serious_events_max = df['serious Adverse Events'].max()\n",
    "serious_events_min = df['serious Adverse Events'].min()\n",
    "serious_events_std = df['serious Adverse Events'].std()\n",
    "\n",
    "print(\"Mean of seriousEvents :\", serious_events_mean)\n",
    "print(\"Max of seriousEvents:\", serious_events_max)\n",
    "print(\"Min of seriousEvents:\", serious_events_min)\n",
    "print(\"Std of seriousEvents:\", serious_events_std)\n",
    "\n",
    "phase_counts = df['Phase'].value_counts()\n",
    "print(\"The number of each phase:\")\n",
    "print(phase_counts)\n",
    "print()\n",
    "\n",
    "# count the number of drug name\n",
    "drug_name_columns = [col for col in df.columns if 'Drug Name' in col]\n",
    "drug_name_count_distribution = df[drug_name_columns].notna().sum(axis=1).value_counts().sort_index()\n",
    "\n",
    "print(\"The number of each drug name:\")\n",
    "print(drug_name_count_distribution)\n",
    "\n",
    "#Check whether drug name includes 'placebo' or not\n",
    "df_str = df[drug_name_columns].astype(str)\n",
    "contains_placebo = df_str.apply(lambda x: x.str.contains('Placebo|placebo', case=False, na=False)).any(axis=1)\n",
    "\n",
    "num_contains_placebo = contains_placebo.sum()\n",
    "num_not_contains_placebo = (~contains_placebo).sum()\n",
    "\n",
    "print(\"The number of data entries with Placebo.:\",num_contains_placebo)\n",
    "print(\"The number of data entries without Placebo.:\",num_not_contains_placebo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
